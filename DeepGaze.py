# -*- coding: utf-8 -*-
"""Saliency.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gnfKJ5JputyPc39S5JXASLVc00rVwQq_

Load The Saliency.zip Dataset
"""

from google.colab import files

# Upload file(s)
uploaded = files.upload()

# List uploaded files
import os
print(os.listdir())

"""Unzip the dataset"""

import zipfile

with zipfile.ZipFile('Saliency4asd.zip', 'r') as zip_ref:
    zip_ref.extractall('Saliency4asd')

"""Clone DeepGaze model from github"""

!git clone https://github.com/matthias-k/DeepGaze.git

"""Importing library functions for that model manually"""

!pip install torch torchvision numpy scipy matplotlib h5py

!ls "/content/DeepGaze"

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/DeepGaze"
!pip install -e /content/DeepGaze

!wget https://github.com/matthias-k/DeepGaze/releases/download/v1.0.0/centerbias_mit1003.npy

"""DeepGaze installation"""

import numpy as np
from scipy.misc import face
from scipy.ndimage import zoom
from scipy.special import logsumexp
import torch

import deepgaze_pytorch

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# Load the pretrained DeepGazeIIE model
model = deepgaze_pytorch.DeepGazeIIE(pretrained=True).to(DEVICE)

# Load an example image
image = face()

# Load precomputed centerbias log density
centerbias_template = np.load('centerbias_mit1003.npy')

# Rescale to match image size
centerbias = zoom(centerbias_template, (image.shape[0]/centerbias_template.shape[0],
                                        image.shape[1]/centerbias_template.shape[1]),
                  order=0, mode='nearest')

# Renormalize log density
centerbias -= logsumexp(centerbias)

# Convert to tensors
image_tensor = torch.tensor([image.transpose(2, 0, 1)]).float().to(DEVICE)
centerbias_tensor = torch.tensor([centerbias]).float().to(DEVICE)

# Get model predictions
log_density_prediction = model(image_tensor, centerbias_tensor)

print("Model output shape:", log_density_prediction.shape)

"""Generating saliency Map for Single Image"""

import torch
from deepgaze_pytorch import DeepGazeIIE
import numpy as np
from scipy.ndimage import zoom
from scipy.special import logsumexp
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt

# Specify device
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# Load DeepGazeIIE model
def load_deepgaze():
    model = DeepGazeIIE(pretrained=True).to(DEVICE)
    model.eval()  # Set model to evaluation mode
    return model

# Preprocess image to match input requirements
def preprocess_image(image):
    transform = transforms.Compose([transforms.ToTensor()])
    return transform(image).unsqueeze(0).to(DEVICE)  # Add batch dimension

# Load centerbias (MIT1003) data
def load_centerbias():
    centerbias_template = np.load('centerbias_mit1003.npy')
    return centerbias_template

# Generate saliency map for a given image
def generate_saliency_map(model, image):
    # Prepare image and centerbias
    image_tensor = preprocess_image(image)
    centerbias = load_centerbias()

    # Rescale centerbias to match image size
    centerbias_rescaled = zoom(centerbias, (image_tensor.shape[2]/centerbias.shape[0], image_tensor.shape[3]/centerbias.shape[1]), order=0, mode='nearest')
    centerbias_rescaled -= logsumexp(centerbias_rescaled)  # Normalize log density

    centerbias_tensor = torch.tensor([centerbias_rescaled]).to(DEVICE)

    with torch.no_grad():
        saliency_map = model(image_tensor, centerbias_tensor)

    return saliency_map

# Main function to run the model
def main(image_path):
    image = Image.open(image_path).convert("RGB")  # Open image and convert to RGB
    model = load_deepgaze()

    saliency_map = generate_saliency_map(model, image)
    print("Saliency map generated!")

    # Visualize the saliency map
    saliency_map_image = saliency_map.squeeze().cpu().numpy()  # Remove batch and move to CPU
    plt.imshow(saliency_map_image, cmap='hot')
    plt.colorbar()
    plt.show()

if __name__ == '__main__':
    image_path = '/content/Saliency4asd/Saliency4asd/Images/1.png'  # Replace with the path to your image
    main(image_path)

"""Run this if youu only want to delete generated saliency folder. OTHERWISE Don't touch this YOU WILL LOSE 1.5 HOURS FROM YOUR LIFE"""

import shutil

folder_path = "/content/saliency_maps"  # Change to your folder path
shutil.rmtree(folder_path)  # Delete folder and all its contents
print(f"Deleted folder: {folder_path}")

"""Generating saliency Map for all Images"""

import torch
from deepgaze_pytorch import DeepGazeIIE
import numpy as np
from scipy.ndimage import zoom
from scipy.special import logsumexp
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import os
import zipfile

# Specify device
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# Load DeepGazeIIE model
def load_deepgaze():
    model = DeepGazeIIE(pretrained=True).to(DEVICE)
    model.eval()  # Set model to evaluation mode
    return model

# Preprocess image to match input requirements
def preprocess_image(image):
    transform = transforms.Compose([transforms.ToTensor()])
    return transform(image).unsqueeze(0).to(DEVICE)  # Add batch dimension

# Load centerbias (MIT1003) data
def load_centerbias():
    centerbias_template = np.load('centerbias_mit1003.npy')
    return centerbias_template

# Generate saliency map for a given image
def generate_saliency_map(model, image):
    # Prepare image and centerbias
    image_tensor = preprocess_image(image)
    centerbias = load_centerbias()

    # Rescale centerbias to match image size
    centerbias_rescaled = zoom(centerbias, (image_tensor.shape[2]/centerbias.shape[0], image_tensor.shape[3]/centerbias.shape[1]), order=0, mode='nearest')
    centerbias_rescaled -= logsumexp(centerbias_rescaled)  # Normalize log density

    centerbias_tensor = torch.tensor([centerbias_rescaled]).to(DEVICE)

    with torch.no_grad():
        saliency_map = model(image_tensor, centerbias_tensor)

    return saliency_map

# Function to save or display the saliency map
def save_or_display_saliency_map(saliency_map, image_name):
    saliency_map_image = saliency_map.squeeze().cpu().numpy()  # Remove batch and move to CPU
    plt.imshow(saliency_map_image, cmap='hot')
    plt.colorbar()
    plt.title(f'Saliency Map for {image_name}')

    # Save the saliency map in a folder
    save_path = f"/content/saliency_maps/{image_name}"  # Save in 'saliency_maps' folder
    plt.savefig(save_path)  # Save the saliency map image
    plt.close()  # Close the plot to avoid overlapping

    return save_path  # Return the saved path for downloading

# Function to download all saliency maps as a zip file
def download_saliency_maps():
    """
    Compress all saliency maps into a zip file and download it.
    """
    # Create a zip file of all saliency maps
    saliency_dir = "/content/saliency_maps"
    zip_path = "/content/saliency_maps.zip"

    with zipfile.ZipFile(zip_path, 'w') as zipf:
        for root, dirs, files in os.walk(saliency_dir):
            for file in files:
                if file.endswith('.png'):  # Adjust file extensions as needed
                    file_path = os.path.join(root, file)
                    zipf.write(file_path, os.path.relpath(file_path, saliency_dir))

    # Download the zip file (works in Google Colab)
    try:
        from google.colab import files
        files.download(zip_path)
        print(f"Saliency maps downloaded as {zip_path}")
    except (ImportError, AttributeError):
        print(f"Zip file created at {zip_path}")
        print("To download: In Colab file browser, right-click the zip file and select 'Download'")

# Main function to run the model on all images in the directory
def main(directory_path):
    # Create the saliency maps directory if it doesn't exist
    os.makedirs("/content/saliency_maps", exist_ok=True)

    model = load_deepgaze()
    # Iterate over all files in the directory
    for filename in os.listdir(directory_path):
        if filename.endswith(".png") or filename.endswith(".jpg") or filename.endswith(".jpeg"):  # Change file types as needed
            image_path = os.path.join(directory_path, filename)
            image = Image.open(image_path).convert("RGB")  # Open image and convert to RGB

            saliency_map = generate_saliency_map(model, image)
            print(f"Saliency map generated for {filename}!")

            # Save or display the saliency map and get the path
            save_path = save_or_display_saliency_map(saliency_map, filename)

    # Trigger the download of all saliency maps as a zip file
    download_saliency_maps()

if __name__ == '__main__':
    directory_path = '/content/Saliency4asd/Saliency4asd/Images'  # Replace with your directory path
    main(directory_path)

from PIL import Image
import numpy as np

def load_fixation_map(map_path):
    """Loads fixation map as a numpy array"""
    fixation_map = Image.open(map_path).convert("L")  # Convert to grayscale
    return np.array(fixation_map)  # Convert to numpy array

# Example: Load an ASD and TD fixation map
asd_map = load_fixation_map('/content/Saliency4asd/Saliency4asd/ASD_FixMaps/100_s.png')
td_map = load_fixation_map('/content/Saliency4asd/Saliency4asd/TD_FixMaps/100_s.png')
print("Done")

import cv2

def resize_map(fixation_map, target_shape):
    """Resizes fixation map to match target shape (height, width)."""
    return cv2.resize(fixation_map, (target_shape[1], target_shape[0]))  # Resize to match (H, W)

# Assume saliency map has shape (height, width)
saliency_map = np.array(Image.open('/content/saliency_maps/1.png').convert("L"))  # Example

asd_map_resized = resize_map(asd_map, saliency_map.shape)
td_map_resized = resize_map(td_map, saliency_map.shape)
print("Done")

"""Single image comparison"""

import matplotlib.pyplot as plt

def visualize_comparison(td_map, asd_map, saliency_map, image_name):
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))

    axs[0].imshow(td_map, cmap='hot')
    axs[0].set_title(f"TD Fixation Map: {image_name}")
    axs[0].axis('off')

    axs[1].imshow(asd_map, cmap='hot')
    axs[1].set_title(f"ASD Fixation Map: {image_name}")
    axs[1].axis('off')

    axs[2].imshow(saliency_map, cmap='hot')
    axs[2].set_title(f"Generated Saliency Map: {image_name}")
    axs[2].axis('off')

    plt.show()

# Example usage
visualize_comparison(td_map_resized, asd_map_resized, saliency_map, "1.png")

"""USING MATRIC

Matrix install
"""

!pip install scipy numpy opencv-python

"""Having the same image name for three folders"""

import os

saliency_dir = '/content/saliency_maps'
td_fix_dir = '/content/Saliency4asd/Saliency4asd/TD_FixMaps/'
asd_fix_dir = '/content/Saliency4asd/Saliency4asd/ASD_FixMaps/'

saliency_files = [f for f in os.listdir(saliency_dir) if f.endswith('.png')]
td_fix_files = [f for f in os.listdir(td_fix_dir) if f.endswith('.png')]
asd_fix_files = [f for f in os.listdir(asd_fix_dir) if f.endswith('.png')]

for saliency_file in saliency_files:
    # Remove the '_s' suffix to match the corresponding fixation map
    base_name = saliency_file.replace('.png', '')

    td_fix_file = f"{base_name}_s.png"
    asd_fix_file = f"{base_name}_s.png"

    if td_fix_file in td_fix_files and asd_fix_file in asd_fix_files:
        td_fix_path = os.path.join(td_fix_dir, td_fix_file)
        asd_fix_path = os.path.join(asd_fix_dir, asd_fix_file)

        print(f"Processing file: {saliency_file}")
        print(f"TD Fixation Path: {td_fix_path}")
        print(f"ASD Fixation Path: {asd_fix_path}")

        # Further processing can be done here
    else:
        print(f"Fixation map not found for {saliency_file}")

from scipy.stats import pearsonr

def calculate_pearson(saliency_map, fixation_map):
    saliency_flat = saliency_map.flatten()
    fixation_flat = fixation_map.flatten()
    correlation, _ = pearsonr(saliency_flat, fixation_flat)
    return correlation

from sklearn.metrics import mean_squared_error

def calculate_mse(saliency_map, fixation_map):
    mse = mean_squared_error(saliency_map.flatten(), fixation_map.flatten())
    return mse

from sklearn.metrics import roc_auc_score

def calculate_auc(saliency_map, fixation_map):
    saliency_flat = saliency_map.flatten()
    fixation_flat = fixation_map.flatten()
    # Use binary or continuous thresholding for AUC calculation
    auc = roc_auc_score(fixation_flat, saliency_flat)
    return auc

!pip install numpy scipy opencv-python pillow scikit-learn

"""CLonning matrix fom git"""

!git clone https://github.com/cvzoya/saliency.git

!git clone https://github.com/matthias-k/saliency-benchmarking.git

"""Comparing TD ASD with Saliency map"""

import os
import numpy as np
from sklearn.metrics import roc_auc_score
import scipy.stats
import cv2
from scipy.stats import entropy
from sklearn.metrics import mean_squared_error
from scipy.stats import pearsonr
from PIL import Image
import pandas as pd
from sklearn.metrics import precision_recall_curve

# Define functions for calculating metrics (same as in your original code)
def calculate_auc(y_true, y_pred):
    return roc_auc_score(y_true.flatten(), y_pred.flatten())

def calculate_cc(y_true, y_pred):
    return pearsonr(y_true.flatten(), y_pred.flatten())[0]

def calculate_mse(y_true, y_pred):
    return mean_squared_error(y_true.flatten(), y_pred.flatten())

def calculate_emd(y_true, y_pred):
    y_true = y_true.astype(np.uint8)
    y_pred = y_pred.astype(np.uint8)
    hist_true = cv2.calcHist([y_true], [0], None, [256], [0, 256])
    hist_pred = cv2.calcHist([y_pred], [0], None, [256], [0, 256])
    return cv2.compareHist(hist_true, hist_pred, cv2.HISTCMP_BHATTACHARYYA)

def calculate_kl_div(y_true, y_pred):
    p = np.histogram(y_true.flatten(), bins=256, range=(0, 256))[0]
    q = np.histogram(y_pred.flatten(), bins=256, range=(0, 256))[0]
    p = p / p.sum()
    q = q / q.sum()
    return entropy(p, q)

def calculate_nss(y_true, y_pred):
    return np.mean(np.multiply(y_true, y_pred))

def calculate_info_gain(y_true, y_pred):
    H_true = entropy(np.histogram(y_true.flatten(), bins=2, range=(0, 2))[0])
    H_true_given_pred = entropy(np.histogram2d(y_true.flatten(), y_pred.flatten(), bins=2, range=[[0, 1], [0, 1]])[0])
    return H_true - H_true_given_pred

def calculate_auc_borji(y_true, y_pred):
    y_true = y_true.flatten()
    y_pred = y_pred.flatten()
    y_pred = np.clip(y_pred, 0, 1)
    precision, recall, _ = precision_recall_curve(y_true, y_pred)
    return roc_auc_score(y_true, y_pred)

def calculate_auc_judd(y_true, y_pred):
    y_true = y_true.flatten()
    y_pred = y_pred.flatten()
    y_pred = np.clip(y_pred, 0, 1)
    precision, recall, _ = precision_recall_curve(y_true, y_pred)
    return roc_auc_score(y_true, y_pred)

def calculate_auc_shuffled(y_true, y_pred):
    shuffled_pred = np.random.permutation(y_pred.flatten())
    return roc_auc_score(y_true.flatten(), shuffled_pred)

# Function to load and resize image
def load_and_resize_image(path, target_shape=(224, 224)):
    img = Image.open(path).convert('L')
    img_resized = img.resize(target_shape, Image.LANCZOS)
    return np.array(img_resized).astype(np.float32)

# Directory paths
saliency_map_dir = '/content/saliency_maps'
td_fix_map_dir = '/content/Saliency4asd/Saliency4asd/TD_FixMaps'
asd_fix_map_dir = '/content/Saliency4asd/Saliency4asd/ASD_FixMaps'

# Get list of image files (assuming all files are PNGs)
saliency_images = [f for f in os.listdir(saliency_map_dir) if f.endswith('.png')]
td_images = [f for f in os.listdir(td_fix_map_dir) if f.endswith('.png')]
asd_images = [f for f in os.listdir(asd_fix_map_dir) if f.endswith('.png')]

# Initialize lists to store results and variables to accumulate sums for averages
total_metrics = {
    "TD AUC_Borji": 0,
    "TD AUC_Judd": 0,
    "TD AUC_Shuffled": 0,
    "TD CC": 0,
    "TD EMD": 0,
    "TD Info Gain": 0,
    "TD KLdiv": 0,
    "TD NSS": 0,
    "ASD AUC_Borji": 0,
    "ASD AUC_Judd": 0,
    "ASD AUC_Shuffled": 0,
    "ASD CC": 0,
    "ASD EMD": 0,
    "ASD Info Gain": 0,
    "ASD KLdiv": 0,
    "ASD NSS": 0
}

# Process each image pair
for saliency_img, td_img, asd_img in zip(saliency_images, td_images, asd_images):
    # Load and resize images
    saliency_map = load_and_resize_image(os.path.join(saliency_map_dir, saliency_img))
    td_fix_map = load_and_resize_image(os.path.join(td_fix_map_dir, td_img))
    asd_fix_map = load_and_resize_image(os.path.join(asd_fix_map_dir, asd_img))

    # Ensure binary format for fixation maps
    td_fix_map = (td_fix_map > 0).astype(np.uint8)
    asd_fix_map = (asd_fix_map > 0).astype(np.uint8)

    # Normalize saliency map
    saliency_map = (saliency_map - np.min(saliency_map)) / (np.max(saliency_map) - np.min(saliency_map))

    # Calculate metrics for TD vs Saliency
    td_auc_borji = calculate_auc_borji(td_fix_map, saliency_map)
    td_auc_judd = calculate_auc_judd(td_fix_map, saliency_map)
    td_auc_shuffled = calculate_auc_shuffled(td_fix_map, saliency_map)
    td_cc = calculate_cc(td_fix_map, saliency_map)
    td_emd = calculate_emd(td_fix_map, saliency_map)
    td_kldiv = calculate_kl_div(td_fix_map, saliency_map)
    td_nss = calculate_nss(td_fix_map, saliency_map)
    td_info_gain = calculate_info_gain(td_fix_map, saliency_map)

    # Calculate metrics for ASD vs Saliency
    asd_auc_borji = calculate_auc_borji(asd_fix_map, saliency_map)
    asd_auc_judd = calculate_auc_judd(asd_fix_map, saliency_map)
    asd_auc_shuffled = calculate_auc_shuffled(asd_fix_map, saliency_map)
    asd_cc = calculate_cc(asd_fix_map, saliency_map)
    asd_emd = calculate_emd(asd_fix_map, saliency_map)
    asd_kldiv = calculate_kl_div(asd_fix_map, saliency_map)
    asd_nss = calculate_nss(asd_fix_map, saliency_map)
    asd_info_gain = calculate_info_gain(asd_fix_map, saliency_map)

    # Accumulate the metrics
    total_metrics["TD AUC_Borji"] += td_auc_borji
    total_metrics["TD AUC_Judd"] += td_auc_judd
    total_metrics["TD AUC_Shuffled"] += td_auc_shuffled
    total_metrics["TD CC"] += td_cc
    total_metrics["TD EMD"] += td_emd
    total_metrics["TD Info Gain"] += td_info_gain
    total_metrics["TD KLdiv"] += td_kldiv
    total_metrics["TD NSS"] += td_nss

    total_metrics["ASD AUC_Borji"] += asd_auc_borji
    total_metrics["ASD AUC_Judd"] += asd_auc_judd
    total_metrics["ASD AUC_Shuffled"] += asd_auc_shuffled
    total_metrics["ASD CC"] += asd_cc
    total_metrics["ASD EMD"] += asd_emd
    total_metrics["ASD Info Gain"] += asd_info_gain
    total_metrics["ASD KLdiv"] += asd_kldiv
    total_metrics["ASD NSS"] += asd_nss

# Calculate average for each metric
num_images = len(saliency_images)  # assuming there are 300 images
average_results = {metric: total / num_images for metric, total in total_metrics.items()}

# Split average results into TD and ASD
td_results = {key: value for key, value in average_results.items() if key.startswith("TD")}
asd_results = {key: value for key, value in average_results.items() if key.startswith("ASD")}

# Prepare results for CSV
results = {
    "Metric": ["AUC_Borji", "AUC_Judd", "AUC_Shuffled", "CC", "MSE", "EMD", "KLdiv", "NSS", "Info Gain"],
    "TD vs Saliency": [td_auc, td_auc_judd, td_auc_shuffled, td_cc, td_mse, td_emd, td_kldiv, td_nss, td_info_gain],
    "ASD vs Saliency": [asd_auc, asd_auc_judd, asd_auc_shuffled, asd_cc, asd_mse, asd_emd, asd_kldiv, asd_nss, asd_info_gain]
}
# Convert the TD and ASD results into separate DataFrames
td_df = pd.DataFrame([td_results])
asd_df = pd.DataFrame([asd_results])

# Save the separate DataFrames to CSV
td_csv_path = "/content/td_saliency_metrics_averages.csv"
asd_csv_path = "/content/asd_saliency_metrics_averages.csv"
td_df.to_csv(td_csv_path, index=False)
asd_df.to_csv(asd_csv_path, index=False)

# Print completion
print(f"TD average metrics have been saved to {td_csv_path}")
print(f"ASD average metrics have been saved to {asd_csv_path}")

from google.colab import files

# Download TD metrics CSV
files.download('/content/td_saliency_metrics_averages.csv')

# Download ASD metrics CSV
files.download('/content/asd_saliency_metrics_averages.csv')