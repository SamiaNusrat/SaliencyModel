# -*- coding: utf-8 -*-
"""salFBnet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XQFzyQnFLqpjvubYihZJzVnnxd8TGh8l
"""

import zipfile

with zipfile.ZipFile('Saliency4asd.zip', 'r') as zip_ref:
    zip_ref.extractall('Saliency4asd')

!git clone https://github.com/gqding/SalFBNet.git

# Commented out IPython magic to ensure Python compatibility.
# %cd SalFBNet
!pip install scikit-learn scipy tensorboard tqdm torchSummaryX

!gdown --folder https://drive.google.com/drive/folders/1tUYgWPZvVn5k8xNZCSuv2lquNOSTzM7X?usp=sharing

import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import numpy as np
import os
import zipfile
import matplotlib.pyplot as plt

# Specify device
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"ðŸ”¥ Using device: {DEVICE}")

# Define paths
salfbnet_model_path = "/content/SalFBNet/pretrained_models/FBNet_Res18Fixed_best_model.pth"  # Path to pre-trained model
image_folder = "/content/Saliency4asd/Saliency4asd/Images"  # Input image directory
output_folder = "/content/saliency_maps"  # Output folder

# Ensure output directory exists
os.makedirs(output_folder, exist_ok=True)

# Define SalFBNet model structure (Must match the architecture used in training)
class SalFBNet(nn.Module):
    def __init__(self):
        super(SalFBNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)
        self.conv2 = nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = torch.sigmoid(self.conv2(x))  # Output between 0 and 1
        return x

# Load pre-trained SalFBNet model
def load_salfbnet():
    model = SalFBNet().to(DEVICE)
    try:
        model.load_state_dict(torch.load(salfbnet_model_path, map_location=DEVICE), strict=False)
        print("âœ… Model loaded successfully")
    except Exception as e:
        print(f"âŒ Error loading model: {e}")
        exit(1)
    model.eval()
    return model

# Preprocess image
def preprocess_image(image):
    transform = transforms.Compose([
        transforms.Resize((224, 224)),  # Resize to match model input size
        transforms.ToTensor(),
    ])
    return transform(image).unsqueeze(0).to(DEVICE)  # Convert image to tensor and add batch dimension

# Generate saliency map
def generate_saliency_map(model, image):
    image_tensor = preprocess_image(image)

    with torch.no_grad():
        saliency_map = model(image_tensor)  # Forward pass

    return saliency_map

# Save saliency map as an image
def save_saliency_map(saliency_map, image_name):
    saliency_map_image = saliency_map.squeeze().cpu().numpy()  # Convert tensor to NumPy
    saliency_map_image = (saliency_map_image - saliency_map_image.min()) / (saliency_map_image.max() - saliency_map_image.min())  # Normalize

    # Convert to image format
    plt.imshow(saliency_map_image, cmap='hot')
    plt.colorbar()
    plt.title(f'Saliency Map for {image_name}')

    save_path = os.path.join(output_folder, image_name)
    plt.savefig(save_path)
    plt.close()

    return save_path

# Compress all saliency maps into a ZIP file
def download_saliency_maps():
    zip_path = "/content/saliency_maps.zip"
    with zipfile.ZipFile(zip_path, 'w') as zipf:
        for file in os.listdir(output_folder):
            if file.endswith(".png"):
                file_path = os.path.join(output_folder, file)
                zipf.write(file_path, os.path.relpath(file_path, output_folder))

    # Download the ZIP file (Colab only)
    try:
        from google.colab import files
        files.download(zip_path)
        print(f"âœ… Saliency maps downloaded as {zip_path}")
    except ImportError:
        print(f"Zip file created at {zip_path}. Manually download from file manager.")

# Main function to process all images in directory
def main(image_directory):
    model = load_salfbnet()

    for filename in os.listdir(image_directory):
        if filename.lower().endswith((".png", ".jpg", ".jpeg")):
            image_path = os.path.join(image_directory, filename)
            image = Image.open(image_path).convert("RGB")  # Open and convert image

            saliency_map = generate_saliency_map(model, image)
            save_path = save_saliency_map(saliency_map, filename)

            print(f"âœ… Saved saliency map: {save_path}")

    # Download all results as ZIP
    download_saliency_maps()

if __name__ == '__main__':
    main(image_folder)

import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
from PIL import Image

# Define folder paths
saliency_folder = "/content/saliency_maps"
td_folder = "/content/Saliency4asd/Saliency4asd/TD_FixMaps"
asd_folder = "/content/Saliency4asd/Saliency4asd/ASD_FixMaps"

# âœ… Function to load fixation maps as numpy arrays
def load_fixation_map(map_path):
    """Loads fixation map as a numpy array."""
    if not map_path or not os.path.exists(map_path):
        return None  # Return None if the file is missing
    fixation_map = Image.open(map_path).convert("L")  # Convert to grayscale
    return np.array(fixation_map)

# âœ… Function to resize maps to match the saliency map size
def resize_map(fixation_map, target_shape):
    """Resizes fixation map to match target shape (height, width)."""
    if fixation_map is None:
        return None  # If no fixation map, return None
    return cv2.resize(fixation_map, (target_shape[1], target_shape[0]))  # Resize to (H, W)

# âœ… Function to find the best matching fixation map
def find_best_match(image_name, folder):
    """Finds the best match for the given image name (ignoring extensions)."""
    base_name = os.path.splitext(image_name)[0]  # Remove extension
    for file in os.listdir(folder):
        if file.startswith(base_name) and file.lower().endswith(('.png', '.jpg', '.jpeg')):  # Match filename + valid extension
            return os.path.join(folder, file)
    return None  # Return None if no match found

# âœ… Function to visualize and compare saliency maps with fixation maps
def visualize_comparison(td_map, asd_map, saliency_map, image_name):
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))

    if td_map is not None:
        axs[0].imshow(td_map, cmap='hot')
        axs[0].set_title(f"TD Fixation Map: {image_name}")
    else:
        axs[0].axis('off')
        axs[0].set_title("No TD Fixation Map")

    if asd_map is not None:
        axs[1].imshow(asd_map, cmap='hot')
        axs[1].set_title(f"ASD Fixation Map: {image_name}")
    else:
        axs[1].axis('off')
        axs[1].set_title("No ASD Fixation Map")

    axs[2].imshow(saliency_map, cmap='hot')
    axs[2].set_title(f"Generated Saliency Map: {image_name}")

    for ax in axs:
        ax.axis("off")

    plt.show()

# âœ… Process all saliency maps
for saliency_name in os.listdir(saliency_folder):
    saliency_path = os.path.join(saliency_folder, saliency_name)

    # **Skip directories and non-image files**
    if not os.path.isfile(saliency_path) or not saliency_name.lower().endswith(('.png', '.jpg', '.jpeg')):
        continue

    # Load saliency map
    saliency_map = np.array(Image.open(saliency_path).convert("L"))

    # Find matching TD and ASD fixation maps
    td_path = find_best_match(saliency_name, td_folder)
    asd_path = find_best_match(saliency_name, asd_folder)

    # Load fixation maps
    td_map = load_fixation_map(td_path)
    asd_map = load_fixation_map(asd_path)

    # Resize fixation maps to match saliency map size
    td_map_resized = resize_map(td_map, saliency_map.shape)
    asd_map_resized = resize_map(asd_map, saliency_map.shape)

    # Skip if both fixation maps are missing
    if td_map_resized is None and asd_map_resized is None:
        print(f"âš ï¸ Skipping {saliency_name}: No matching TD or ASD fixation map found")
        continue

    # Display the comparison
    visualize_comparison(td_map_resized, asd_map_resized, saliency_map, saliency_name)

print("âœ… Comparison complete for all available images.")

!git clone https://github.com/cvzoya/saliency.git

!git clone https://github.com/matthias-k/saliency-benchmarking.git

import numpy as np
from sklearn.metrics import roc_auc_score
import scipy.stats
import cv2
from scipy.stats import entropy, pearsonr
from PIL import Image
import pandas as pd

# AUC Calculation (Borji, Judd, Shuffled)
def calculate_auc(y_true, y_pred):
    return roc_auc_score(y_true.flatten(), y_pred.flatten())

def calculate_auc_judd(y_true, y_pred):
    thresholds = np.linspace(0, 1, 20)
    scores = [roc_auc_score(y_true.flatten(), (y_pred >= t).astype(np.uint8).flatten()) for t in thresholds]
    return np.mean(scores)

def calculate_auc_shuffled(y_true, y_pred, random_fixations):
    return roc_auc_score(y_true.flatten(), y_pred.flatten()) - roc_auc_score(random_fixations.flatten(), y_pred.flatten())

# Pearson Correlation (CC)
def calculate_cc(y_true, y_pred):
    return pearsonr(y_true.flatten(), y_pred.flatten())[0]

# Mean Squared Error (MSE)
def calculate_mse(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

# Earth Mover's Distance (EMD)
def calculate_emd(y_true, y_pred):
    y_true = y_true.astype(np.uint8)
    y_pred = y_pred.astype(np.uint8)
    hist_true = cv2.calcHist([y_true], [0], None, [256], [0, 256])
    hist_pred = cv2.calcHist([y_pred], [0], None, [256], [0, 256])
    return cv2.compareHist(hist_true, hist_pred, cv2.HISTCMP_BHATTACHARYYA)

# Kullback-Leibler Divergence (KLdiv)
def calculate_kl_div(y_true, y_pred):
    p = np.histogram(y_true.flatten(), bins=256, range=(0, 256))[0] + 1e-10
    q = np.histogram(y_pred.flatten(), bins=256, range=(0, 256))[0] + 1e-10
    p = p / p.sum()
    q = q / q.sum()
    return entropy(p, q)

# Normalized Scanpath Saliency (NSS)
def calculate_nss(y_true, y_pred):
    y_pred = (y_pred - np.mean(y_pred)) / (np.std(y_pred) + 1e-10)
    return np.mean(y_true * y_pred)

# Information Gain (Info Gain)
def calculate_info_gain(y_true, y_pred, baseline):
    return calculate_kl_div(y_true, y_pred) - calculate_kl_div(y_true, baseline)

# Load and resize image
def load_and_resize_image(path, target_shape=(224, 224)):
    img = Image.open(path).convert('L')
    img_resized = img.resize(target_shape, Image.LANCZOS)
    return np.array(img_resized).astype(np.float32)

# Load saliency and fixation maps
saliency_map = load_and_resize_image('/content/saliency_maps/100.png')
td_fix_map = load_and_resize_image('/content/Saliency4asd/Saliency4asd/TD_FixMaps/100_s.png')
asd_fix_map = load_and_resize_image('/content/Saliency4asd/Saliency4asd/ASD_FixMaps/100_s.png')
random_fix_map = np.random.randint(0, 2, td_fix_map.shape)  # Generate random fixations

# Convert fixation maps to binary
td_fix_map = (td_fix_map > 0).astype(np.uint8)
asd_fix_map = (asd_fix_map > 0).astype(np.uint8)

# Normalize saliency map
td_saliency_map = (saliency_map - np.min(saliency_map)) / (np.max(saliency_map) - np.min(saliency_map))

# Compute metrics for TD vs Saliency
td_auc = calculate_auc(td_fix_map, td_saliency_map)
td_auc_judd = calculate_auc_judd(td_fix_map, td_saliency_map)
td_auc_shuffled = calculate_auc_shuffled(td_fix_map, td_saliency_map, random_fix_map)
td_cc = calculate_cc(td_fix_map, td_saliency_map)
td_mse = calculate_mse(td_fix_map, td_saliency_map)
td_emd = calculate_emd(td_fix_map, td_saliency_map)
td_kldiv = calculate_kl_div(td_fix_map, td_saliency_map)
td_nss = calculate_nss(td_fix_map, td_saliency_map)
td_info_gain = calculate_info_gain(td_fix_map, td_saliency_map, random_fix_map)

# Compute metrics for ASD vs Saliency
asd_auc = calculate_auc(asd_fix_map, td_saliency_map)
asd_auc_judd = calculate_auc_judd(asd_fix_map, td_saliency_map)
asd_auc_shuffled = calculate_auc_shuffled(asd_fix_map, td_saliency_map, random_fix_map)
asd_cc = calculate_cc(asd_fix_map, td_saliency_map)
asd_mse = calculate_mse(asd_fix_map, td_saliency_map)
asd_emd = calculate_emd(asd_fix_map, td_saliency_map)
asd_kldiv = calculate_kl_div(asd_fix_map, td_saliency_map)
asd_nss = calculate_nss(asd_fix_map, td_saliency_map)
asd_info_gain = calculate_info_gain(asd_fix_map, td_saliency_map, random_fix_map)

# Prepare results for CSV
results = {
    "Metric": ["AUC_Borji", "AUC_Judd", "AUC_Shuffled", "CC", "MSE", "EMD", "KLdiv", "NSS", "Info Gain"],
    "TD vs Saliency": [td_auc, td_auc_judd, td_auc_shuffled, td_cc, td_mse, td_emd, td_kldiv, td_nss, td_info_gain],
    "ASD vs Saliency": [asd_auc, asd_auc_judd, asd_auc_shuffled, asd_cc, asd_mse, asd_emd, asd_kldiv, asd_nss, asd_info_gain]
}

df = pd.DataFrame(results)
df.to_csv("/content/saliency_metrics.csv", index=False)

# Print Results
print("TD vs Saliency Metrics:")
print(f"AUC_Borji: {td_auc}, AUC_Judd: {td_auc_judd}, AUC_Shuffled: {td_auc_shuffled}, CC: {td_cc}, MSE: {td_mse}, EMD: {td_emd}, KLdiv: {td_kldiv}, NSS: {td_nss}, Info Gain: {td_info_gain}")

print("\nASD vs Saliency Metrics:")
print(f"AUC_Borji: {asd_auc}, AUC_Judd: {asd_auc_judd}, AUC_Shuffled: {asd_auc_shuffled}, CC: {asd_cc}, MSE: {asd_mse}, EMD: {asd_emd}, KLdiv: {asd_kldiv}, NSS: {asd_nss}, Info Gain: {asd_info_gain}")

print("\nMetrics saved to CSV: /content/saliency_metrics.csv")